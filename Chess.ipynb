{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPNslvrdLlv2H6QJsXT71jA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09ca5c6b0586427fa8b6798b5dbac92a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1a14f20929143ecb53d7c485dbac441",
              "IPY_MODEL_127c2682d0fe48a1b5740f67d3dc2177",
              "IPY_MODEL_1a83164ad420459db379021dc75896b8"
            ],
            "layout": "IPY_MODEL_0871ea34bc0b446fb3a6f43aeccd7daf"
          }
        },
        "c1a14f20929143ecb53d7c485dbac441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a44f18fbb74945a985a4e54dfcc5263b",
            "placeholder": "​",
            "style": "IPY_MODEL_fe4a46950f27420697827805d6504041",
            "value": "Parsing NDJSON: "
          }
        },
        "127c2682d0fe48a1b5740f67d3dc2177": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e67b72557862477991e6b986ab1d0444",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aeb489efad7f43dd81e1c607794aeb6e",
            "value": 1
          }
        },
        "1a83164ad420459db379021dc75896b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56a2c7442f614483b66092a27cc0acf1",
            "placeholder": "​",
            "style": "IPY_MODEL_13472c5bdbf040219556b61ae8ff0346",
            "value": " 598670/? [1:27:11&lt;00:00, 96.45 lignes/s, parties=515,000, positions=44,403,261, RAM_Mo=743]"
          }
        },
        "0871ea34bc0b446fb3a6f43aeccd7daf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a44f18fbb74945a985a4e54dfcc5263b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe4a46950f27420697827805d6504041": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e67b72557862477991e6b986ab1d0444": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "aeb489efad7f43dd81e1c607794aeb6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56a2c7442f614483b66092a27cc0acf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13472c5bdbf040219556b61ae8ff0346": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaximusDonald/medipass/blob/main/Chess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cellule 0 – Installation et imports"
      ],
      "metadata": {
        "id": "bYmTklzm73qY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uy6V1vrVzf8C",
        "outputId": "c04fc405-8bab-44b3-9774-6c3b9173ebbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/6.1 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for chess (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "PyTorch     : 2.10.0+cu128\n",
            "Chess       : 1.11.2\n",
            "CUDA dispo  : True\n",
            "GPU         : Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# CELLULE 0 – Installation des dépendances\n",
        "# ============================================================\n",
        "!pip install python-chess --quiet\n",
        "!pip install h5py --quiet\n",
        "\n",
        "import h5py\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import chess\n",
        "import chess.pgn\n",
        "import io\n",
        "import pickle\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from typing import List, Tuple, Optional\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Reproductibilité\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# Versions\n",
        "print(f\"PyTorch     : {torch.__version__}\")\n",
        "print(f\"Chess       : {chess.__version__}\")\n",
        "print(f\"CUDA dispo  : {torch.cuda.is_available()}\")\n",
        "print(f\"GPU         : {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cellule 1 – Montage Google Drive et configuration des chemins"
      ],
      "metadata": {
        "id": "OxyO-VZW8Dch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELLULE 1 – Google Drive + chemins\n",
        "# ============================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ── À MODIFIER selon ton organisation Drive ──────────────────\n",
        "NDJSON_PATH   = \"/content/drive/MyDrive/chess/lichess_games.ndjson\"\n",
        "OUTPUT_DIR    = \"/content/drive/MyDrive/chess/dataset_processed\"\n",
        "# ─────────────────────────────────────────────────────────────\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "POSITIONS_PATH = os.path.join(OUTPUT_DIR, \"positions.npz\")\n",
        "META_PATH      = os.path.join(OUTPUT_DIR, \"meta.pkl\")\n",
        "\n",
        "print(f\"Source      : {NDJSON_PATH}\")\n",
        "print(f\"Destination : {OUTPUT_DIR}\")\n",
        "print(f\"Fichier     : {os.path.exists(NDJSON_PATH)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPuw-g_i6HWZ",
        "outputId": "4df5a37e-8ef7-43ac-edd7-68d20800df2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Source      : /content/drive/MyDrive/chess/lichess_games.ndjson\n",
            "Destination : /content/drive/MyDrive/chess/dataset_processed\n",
            "Fichier     : True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cellule 2 – Encodage UCI → index (4672 coups)"
      ],
      "metadata": {
        "id": "jCIL7LzZ8JwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELLULE 2 – Mapping UCI moves ↔ index (4672 coups)\n",
        "# Encodage standard Leela/AlphaZero\n",
        "# ============================================================\n",
        "\n",
        "def build_move_index() -> Tuple[dict, dict]:\n",
        "    \"\"\"\n",
        "    Construit deux dictionnaires :\n",
        "      uci2idx : str  -> int  (coup UCI -> index 0..4671)\n",
        "      idx2uci : int  -> str  (index -> coup UCI)\n",
        "    Couvre tous les coups légaux possibles aux échecs standard.\n",
        "    \"\"\"\n",
        "    moves = []\n",
        "\n",
        "    # Toutes les combinaisons source → destination\n",
        "    squares = list(chess.SQUARES)  # 0..63\n",
        "    for from_sq in squares:\n",
        "        for to_sq in squares:\n",
        "            if from_sq == to_sq:\n",
        "                continue\n",
        "            # Coup normal\n",
        "            moves.append(chess.Move(from_sq, to_sq).uci())\n",
        "            # Promotions (uniquement sur les rangées de promotion)\n",
        "            from_rank = chess.square_rank(from_sq)\n",
        "            to_rank   = chess.square_rank(to_sq)\n",
        "            if (from_rank == 6 and to_rank == 7) or \\\n",
        "               (from_rank == 1 and to_rank == 0):\n",
        "                for promo in [chess.QUEEN, chess.ROOK,\n",
        "                              chess.BISHOP, chess.KNIGHT]:\n",
        "                    moves.append(chess.Move(from_sq, to_sq, promo).uci())\n",
        "\n",
        "    # Dédoublonnage + tri pour stabilité\n",
        "    moves = sorted(set(moves))\n",
        "    uci2idx = {m: i for i, m in enumerate(moves)}\n",
        "    idx2uci = {i: m for m, i in uci2idx.items()}\n",
        "\n",
        "    print(f\"Taille du vocabulaire de coups : {len(moves)}\")\n",
        "    return uci2idx, idx2uci\n",
        "\n",
        "UCI2IDX, IDX2UCI = build_move_index()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdzQC1he6oqa",
        "outputId": "2fa93db9-91c3-4a01-a8a4-f9e4407de774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taille du vocabulaire de coups : 4544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cellule 3 – Encodage d'une position en tenseur [16, 8, 8]"
      ],
      "metadata": {
        "id": "aVZRwzLU8Sig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELLULE 3 – Encodage position → tenseur [16, 8, 8]\n",
        "# ============================================================\n",
        "\n",
        "# Ordre des pièces : P N B R Q K pour chaque couleur\n",
        "PIECE_ORDER = [\n",
        "    chess.PAWN, chess.KNIGHT, chess.BISHOP,\n",
        "    chess.ROOK, chess.QUEEN,  chess.KING\n",
        "]\n",
        "\n",
        "def board_to_tensor(board: chess.Board) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Encode un chess.Board en tenseur float32 [16, 8, 8].\n",
        "\n",
        "    Plans :\n",
        "      0– 5  : pièces blanches (P N B R Q K)\n",
        "      6–11  : pièces noires   (p n b r q k)\n",
        "      12    : trait (1.0 = blancs, 0.0 = noirs)\n",
        "      13    : droits de roque (4 cases encodées)\n",
        "      14    : case en passant (1.0 sur la case cible)\n",
        "      15    : compteur demi-coups sans capture (normalisé)\n",
        "    \"\"\"\n",
        "    tensor = np.zeros((16, 8, 8), dtype=np.float32)\n",
        "\n",
        "    # Plans 0–11 : pièces\n",
        "    for plane_idx, piece_type in enumerate(PIECE_ORDER):\n",
        "        # Blancs\n",
        "        for sq in board.pieces(piece_type, chess.WHITE):\n",
        "            r, c = divmod(sq, 8)\n",
        "            tensor[plane_idx, r, c] = 1.0\n",
        "        # Noirs\n",
        "        for sq in board.pieces(piece_type, chess.BLACK):\n",
        "            r, c = divmod(sq, 8)\n",
        "            tensor[plane_idx + 6, r, c] = 1.0\n",
        "\n",
        "    # Plan 12 : trait\n",
        "    tensor[12, :, :] = 1.0 if board.turn == chess.WHITE else 0.0\n",
        "\n",
        "    # Plan 13 : droits de roque (encodés sur 4 cases fixes)\n",
        "    if board.has_kingside_castling_rights(chess.WHITE):\n",
        "        tensor[13, 0, 7] = 1.0\n",
        "    if board.has_queenside_castling_rights(chess.WHITE):\n",
        "        tensor[13, 0, 0] = 1.0\n",
        "    if board.has_kingside_castling_rights(chess.BLACK):\n",
        "        tensor[13, 7, 7] = 1.0\n",
        "    if board.has_queenside_castling_rights(chess.BLACK):\n",
        "        tensor[13, 7, 0] = 1.0\n",
        "\n",
        "    # Plan 14 : en passant\n",
        "    if board.ep_square is not None:\n",
        "        r, c = divmod(board.ep_square, 8)\n",
        "        tensor[14, r, c] = 1.0\n",
        "\n",
        "    # Plan 15 : demi-coups sans capture (normalisé sur 100)\n",
        "    tensor[15, :, :] = min(board.halfmove_clock / 100.0, 1.0)\n",
        "\n",
        "    return tensor\n",
        "\n",
        "\n",
        "def move_to_index(move: chess.Move, uci2idx: dict) -> Optional[int]:\n",
        "    \"\"\"Convertit un coup chess.Move en index entier. Retourne None si inconnu.\"\"\"\n",
        "    uci = move.uci()\n",
        "    return uci2idx.get(uci, None)"
      ],
      "metadata": {
        "id": "NOESfUot65KA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cellule 4 – Parser NDJSON et extraction des positions"
      ],
      "metadata": {
        "id": "GSwmkut38Y9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELLULE 4 – Parser NDJSON en streaming + extraction\n",
        "# ============================================================\n",
        "\n",
        "def parse_ndjson_to_arrays(\n",
        "    ndjson_path: str,\n",
        "    uci2idx: dict,\n",
        "    min_elo: int = 1800,\n",
        "    max_games: Optional[int] = None,\n",
        "    skip_first_n_moves: int = 0\n",
        ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Lit le fichier NDJSON en streaming, filtre les parties standard,\n",
        "    et extrait (position, coup joué, résultat) pour chaque demi-coup.\n",
        "\n",
        "    Args:\n",
        "        ndjson_path       : chemin vers le fichier .ndjson\n",
        "        uci2idx           : dictionnaire UCI -> index\n",
        "        min_elo           : Elo minimum des deux joueurs\n",
        "        max_games         : limite de parties (None = toutes)\n",
        "        skip_first_n_moves: ignore les N premiers coups (théorie d'ouverture)\n",
        "\n",
        "    Returns:\n",
        "        positions  : np.ndarray float16 [N, 16, 8, 8]\n",
        "        move_idxs  : np.ndarray int32   [N]\n",
        "        outcomes   : np.ndarray float32 [N]  (1.0 / 0.5 / 0.0)\n",
        "    \"\"\"\n",
        "\n",
        "    positions_list  = []\n",
        "    move_idxs_list  = []\n",
        "    outcomes_list   = []\n",
        "\n",
        "    games_parsed    = 0\n",
        "    games_skipped   = 0\n",
        "    positions_total = 0\n",
        "    errors          = 0\n",
        "\n",
        "    with open(ndjson_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line_num, line in enumerate(tqdm(f, desc=\"Parsing NDJSON\")):\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                game = json.loads(line)\n",
        "            except json.JSONDecodeError:\n",
        "                errors += 1\n",
        "                continue\n",
        "\n",
        "            # ── Filtres ───────────────────────────────────────────\n",
        "            if game.get(\"variant\", \"\") != \"standard\":\n",
        "                games_skipped += 1\n",
        "                continue\n",
        "\n",
        "            if not game.get(\"rated\", False):\n",
        "                games_skipped += 1\n",
        "                continue\n",
        "\n",
        "            players  = game.get(\"players\", {})\n",
        "            w_rating = players.get(\"white\", {}).get(\"rating\", 0)\n",
        "            b_rating = players.get(\"black\", {}).get(\"rating\", 0)\n",
        "            if w_rating < min_elo or b_rating < min_elo:\n",
        "                games_skipped += 1\n",
        "                continue\n",
        "\n",
        "            moves_san = game.get(\"moves\", \"\").strip()\n",
        "            if not moves_san:\n",
        "                games_skipped += 1\n",
        "                continue\n",
        "\n",
        "            # ── Résultat de la partie ─────────────────────────────\n",
        "            winner = game.get(\"winner\", None)\n",
        "            if winner == \"white\":\n",
        "                outcome_white = 1.0\n",
        "            elif winner == \"black\":\n",
        "                outcome_white = 0.0\n",
        "            else:\n",
        "                outcome_white = 0.5   # nulle ou non terminée\n",
        "\n",
        "            # ── Replay de la partie ───────────────────────────────\n",
        "            board = chess.Board()\n",
        "            try:\n",
        "                pgn_io  = io.StringIO(\n",
        "                    f'[Variant \"Standard\"]\\n\\n{moves_san}'\n",
        "                )\n",
        "                pgn_game = chess.pgn.read_game(pgn_io)\n",
        "                if pgn_game is None:\n",
        "                    games_skipped += 1\n",
        "                    continue\n",
        "                moves_list = list(pgn_game.mainline_moves())\n",
        "            except Exception:\n",
        "                errors += 1\n",
        "                continue\n",
        "\n",
        "            if len(moves_list) < skip_first_n_moves + 2:\n",
        "                games_skipped += 1\n",
        "                continue\n",
        "\n",
        "            for move_num, move in enumerate(moves_list):\n",
        "                if move_num < skip_first_n_moves:\n",
        "                    board.push(move)\n",
        "                    continue\n",
        "\n",
        "                # Vérification légalité\n",
        "                if move not in board.legal_moves:\n",
        "                    break\n",
        "\n",
        "                # Encodage position\n",
        "                tensor = board_to_tensor(board)\n",
        "\n",
        "                # Encodage coup\n",
        "                idx = move_to_index(move, uci2idx)\n",
        "                if idx is None:\n",
        "                    board.push(move)\n",
        "                    continue\n",
        "\n",
        "                # Résultat du point de vue du joueur au trait\n",
        "                if board.turn == chess.WHITE:\n",
        "                    outcome = outcome_white\n",
        "                else:\n",
        "                    outcome = 1.0 - outcome_white\n",
        "\n",
        "                positions_list.append(tensor)\n",
        "                move_idxs_list.append(idx)\n",
        "                outcomes_list.append(outcome)\n",
        "                positions_total += 1\n",
        "\n",
        "                board.push(move)\n",
        "\n",
        "            games_parsed += 1\n",
        "            if max_games and games_parsed >= max_games:\n",
        "                break\n",
        "\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Parties parsées   : {games_parsed:>10,}\")\n",
        "    print(f\"Parties ignorées  : {games_skipped:>10,}\")\n",
        "    print(f\"Erreurs           : {errors:>10,}\")\n",
        "    print(f\"Positions totales : {positions_total:>10,}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    # Conversion en arrays numpy\n",
        "    positions  = np.array(positions_list,  dtype=np.float16)\n",
        "    move_idxs  = np.array(move_idxs_list,  dtype=np.int32)\n",
        "    outcomes   = np.array(outcomes_list,   dtype=np.float32)\n",
        "\n",
        "    return positions, move_idxs, outcomes"
      ],
      "metadata": {
        "id": "4Lla0Hi_7EgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cellule 5 – Lancement du parsing et sauvegarde"
      ],
      "metadata": {
        "id": "akPkRle98kP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELLULE 5 bis – Parser NDJSON → HDF5 en streaming\n",
        "# RAM utilisée à tout instant : < 500 Mo\n",
        "# ============================================================\n",
        "\n",
        "HDF5_PATH = os.path.join(OUTPUT_DIR, \"chess_dataset.h5\")\n",
        "CHUNK_SIZE = 10_000   # positions écrites sur disque toutes les 10k\n",
        "\n",
        "def parse_ndjson_to_hdf5(\n",
        "    ndjson_path:        str,\n",
        "    hdf5_path:          str,\n",
        "    uci2idx:            dict,\n",
        "    min_elo:            int   = 1800,\n",
        "    max_games:          int   = None,\n",
        "    skip_first_n_moves: int   = 0,\n",
        "    chunk_size:         int   = CHUNK_SIZE\n",
        "):\n",
        "    \"\"\"\n",
        "    Parse le NDJSON en streaming et écrit les positions\n",
        "    dans un fichier HDF5 chunk par chunk.\n",
        "    Ne garde jamais plus de `chunk_size` positions en RAM.\n",
        "    \"\"\"\n",
        "\n",
        "    # Buffers temporaires (vidés toutes les chunk_size positions)\n",
        "    buf_positions = []\n",
        "    buf_moves     = []\n",
        "    buf_outcomes  = []\n",
        "\n",
        "    games_parsed    = 0\n",
        "    games_skipped   = 0\n",
        "    positions_total = 0\n",
        "    errors          = 0\n",
        "\n",
        "    def flush_buffer(h5f, buf_pos, buf_mov, buf_out, total_written):\n",
        "        \"\"\"Écrit le buffer courant dans le HDF5 et le vide.\"\"\"\n",
        "        n = len(buf_mov)\n",
        "        if n == 0:\n",
        "            return total_written\n",
        "\n",
        "        arr_pos = np.array(buf_pos, dtype=np.float16)\n",
        "        arr_mov = np.array(buf_mov, dtype=np.int32)\n",
        "        arr_out = np.array(buf_out, dtype=np.float32)\n",
        "\n",
        "        # Agrandit les datasets HDF5 et écrit\n",
        "        new_size = total_written + n\n",
        "        h5f[\"positions\"].resize(new_size, axis=0)\n",
        "        h5f[\"move_idxs\"].resize(new_size, axis=0)\n",
        "        h5f[\"outcomes\"].resize(new_size, axis=0)\n",
        "\n",
        "        h5f[\"positions\"][total_written:new_size] = arr_pos\n",
        "        h5f[\"move_idxs\"][total_written:new_size] = arr_mov\n",
        "        h5f[\"outcomes\"][total_written:new_size]  = arr_out\n",
        "\n",
        "        return new_size\n",
        "\n",
        "    # Création du fichier HDF5 avec datasets extensibles\n",
        "    with h5py.File(hdf5_path, \"w\") as h5f:\n",
        "        h5f.create_dataset(\n",
        "            \"positions\",\n",
        "            shape=(0, 16, 8, 8),\n",
        "            maxshape=(None, 16, 8, 8),\n",
        "            dtype=np.float16,\n",
        "            chunks=(chunk_size, 16, 8, 8),\n",
        "            compression=\"lzf\"   # compression rapide (pas lente comme gzip)\n",
        "        )\n",
        "        h5f.create_dataset(\n",
        "            \"move_idxs\",\n",
        "            shape=(0,),\n",
        "            maxshape=(None,),\n",
        "            dtype=np.int32,\n",
        "            chunks=(chunk_size,)\n",
        "        )\n",
        "        h5f.create_dataset(\n",
        "            \"outcomes\",\n",
        "            shape=(0,),\n",
        "            maxshape=(None,),\n",
        "            dtype=np.float32,\n",
        "            chunks=(chunk_size,)\n",
        "        )\n",
        "\n",
        "        total_written = 0\n",
        "\n",
        "        with open(ndjson_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            pbar = tqdm(f, desc=\"Parsing NDJSON\", unit=\" lignes\")\n",
        "            for line in pbar:\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "\n",
        "                # ── Parse JSON ───────────────────────────────────\n",
        "                try:\n",
        "                    game = json.loads(line)\n",
        "                except json.JSONDecodeError:\n",
        "                    errors += 1\n",
        "                    continue\n",
        "\n",
        "                # ── Filtres ──────────────────────────────────────\n",
        "                if game.get(\"variant\", \"\") != \"standard\":\n",
        "                    games_skipped += 1\n",
        "                    continue\n",
        "\n",
        "                if not game.get(\"rated\", False):\n",
        "                    games_skipped += 1\n",
        "                    continue\n",
        "\n",
        "                players  = game.get(\"players\", {})\n",
        "                w_rating = players.get(\"white\", {}).get(\"rating\", 0)\n",
        "                b_rating = players.get(\"black\", {}).get(\"rating\", 0)\n",
        "                if w_rating < min_elo or b_rating < min_elo:\n",
        "                    games_skipped += 1\n",
        "                    continue\n",
        "\n",
        "                moves_san = game.get(\"moves\", \"\").strip()\n",
        "                if not moves_san:\n",
        "                    games_skipped += 1\n",
        "                    continue\n",
        "\n",
        "                # ── Résultat ─────────────────────────────────────\n",
        "                winner = game.get(\"winner\", None)\n",
        "                if winner == \"white\":\n",
        "                    outcome_white = 1.0\n",
        "                elif winner == \"black\":\n",
        "                    outcome_white = 0.0\n",
        "                else:\n",
        "                    outcome_white = 0.5\n",
        "\n",
        "                # ── Replay ───────────────────────────────────────\n",
        "                board = chess.Board()\n",
        "                try:\n",
        "                    pgn_io   = io.StringIO(\n",
        "                        f'[Variant \"Standard\"]\\n\\n{moves_san}'\n",
        "                    )\n",
        "                    pgn_game = chess.pgn.read_game(pgn_io)\n",
        "                    if pgn_game is None:\n",
        "                        games_skipped += 1\n",
        "                        continue\n",
        "                    moves_list = list(pgn_game.mainline_moves())\n",
        "                except Exception:\n",
        "                    errors += 1\n",
        "                    continue\n",
        "\n",
        "                if len(moves_list) < skip_first_n_moves + 2:\n",
        "                    games_skipped += 1\n",
        "                    continue\n",
        "\n",
        "                for move_num, move in enumerate(moves_list):\n",
        "                    if move_num < skip_first_n_moves:\n",
        "                        board.push(move)\n",
        "                        continue\n",
        "\n",
        "                    if move not in board.legal_moves:\n",
        "                        break\n",
        "\n",
        "                    tensor = board_to_tensor(board)\n",
        "                    idx    = move_to_index(move, uci2idx)\n",
        "                    if idx is None:\n",
        "                        board.push(move)\n",
        "                        continue\n",
        "\n",
        "                    outcome = (\n",
        "                        outcome_white\n",
        "                        if board.turn == chess.WHITE\n",
        "                        else 1.0 - outcome_white\n",
        "                    )\n",
        "\n",
        "                    buf_positions.append(tensor)\n",
        "                    buf_moves.append(idx)\n",
        "                    buf_outcomes.append(outcome)\n",
        "                    positions_total += 1\n",
        "\n",
        "                    board.push(move)\n",
        "\n",
        "                    # ── Flush si buffer plein ─────────────────────\n",
        "                    if len(buf_moves) >= chunk_size:\n",
        "                        total_written = flush_buffer(\n",
        "                            h5f,\n",
        "                            buf_positions, buf_moves, buf_outcomes,\n",
        "                            total_written\n",
        "                        )\n",
        "                        buf_positions.clear()\n",
        "                        buf_moves.clear()\n",
        "                        buf_outcomes.clear()\n",
        "\n",
        "                games_parsed += 1\n",
        "\n",
        "                # Mise à jour barre de progression\n",
        "                if games_parsed % 5000 == 0:\n",
        "                    pbar.set_postfix({\n",
        "                        \"parties\": f\"{games_parsed:,}\",\n",
        "                        \"positions\": f\"{positions_total:,}\",\n",
        "                        \"RAM_Mo\": f\"{__import__('psutil').Process().memory_info().rss/1e6:.0f}\"\n",
        "                    })\n",
        "\n",
        "                if max_games and games_parsed >= max_games:\n",
        "                    break\n",
        "\n",
        "        # Flush final du buffer résiduel\n",
        "        if buf_moves:\n",
        "            total_written = flush_buffer(\n",
        "                h5f,\n",
        "                buf_positions, buf_moves, buf_outcomes,\n",
        "                total_written\n",
        "            )\n",
        "\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Parties parsées   : {games_parsed:>10,}\")\n",
        "        print(f\"Parties ignorées  : {games_skipped:>10,}\")\n",
        "        print(f\"Erreurs           : {errors:>10,}\")\n",
        "        print(f\"Positions totales : {total_written:>10,}\")\n",
        "        print(f\"{'='*50}\")\n",
        "        print(f\"HDF5 sauvegardé   : {hdf5_path}\")\n",
        "        print(f\"Taille fichier    : {os.path.getsize(hdf5_path)/1e6:.1f} Mo\")\n",
        "\n",
        "    return total_written\n",
        "\n",
        "\n",
        "# Lancement\n",
        "!pip install psutil --quiet\n",
        "total_positions = parse_ndjson_to_hdf5(\n",
        "    ndjson_path        = NDJSON_PATH,\n",
        "    hdf5_path          = HDF5_PATH,\n",
        "    uci2idx            = UCI2IDX,\n",
        "    min_elo            = 1800,\n",
        "    max_games          = None,\n",
        "    skip_first_n_moves = 0,\n",
        "    chunk_size         = CHUNK_SIZE\n",
        ")\n",
        "\n",
        "# Sauvegarde du mapping UCI\n",
        "with open(META_PATH, \"wb\") as f:\n",
        "    pickle.dump({\"uci2idx\": UCI2IDX, \"idx2uci\": IDX2UCI}, f)\n",
        "print(f\"Meta sauvegardé : {META_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223,
          "referenced_widgets": [
            "09ca5c6b0586427fa8b6798b5dbac92a",
            "c1a14f20929143ecb53d7c485dbac441",
            "127c2682d0fe48a1b5740f67d3dc2177",
            "1a83164ad420459db379021dc75896b8",
            "0871ea34bc0b446fb3a6f43aeccd7daf",
            "a44f18fbb74945a985a4e54dfcc5263b",
            "fe4a46950f27420697827805d6504041",
            "e67b72557862477991e6b986ab1d0444",
            "aeb489efad7f43dd81e1c607794aeb6e",
            "56a2c7442f614483b66092a27cc0acf1",
            "13472c5bdbf040219556b61ae8ff0346"
          ]
        },
        "id": "daKiZ5gr7K9K",
        "outputId": "2f97b1fd-ee3d-409a-94bc-df508e52104f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09ca5c6b0586427fa8b6798b5dbac92a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Parsing NDJSON: 0 lignes [00:00, ? lignes/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Parties parsées   :    519,139\n",
            "Parties ignorées  :     79,531\n",
            "Erreurs           :          0\n",
            "Positions totales : 44,747,887\n",
            "==================================================\n",
            "HDF5 sauvegardé   : /content/drive/MyDrive/chess/dataset_processed/chess_dataset.h5\n",
            "Taille fichier    : 4210.9 Mo\n",
            "Meta sauvegardé : /content/drive/MyDrive/chess/dataset_processed/meta.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cellule 6 – Split train/val/test + Dataset PyTorch"
      ],
      "metadata": {
        "id": "ib1Yuvhh8snc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELLULE 6 bis – ChessHDF5Dataset + splits + DataLoaders\n",
        "# ============================================================\n",
        "\n",
        "class ChessHDF5Dataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset PyTorch qui lit le HDF5 à la volée sans tout charger en RAM.\n",
        "    Chaque worker ouvre sa propre connexion HDF5 (thread-safe).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hdf5_path: str, indices: np.ndarray):\n",
        "        self.hdf5_path = hdf5_path\n",
        "        self.indices   = indices\n",
        "        self._h5f      = None   # ouvert par worker, pas par le process principal\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        # Ouverture lazy (une fois par worker)\n",
        "        if self._h5f is None:\n",
        "            self._h5f = h5py.File(self.hdf5_path, \"r\")\n",
        "\n",
        "        real_idx = int(self.indices[idx])\n",
        "        position = torch.from_numpy(\n",
        "            self.hdf5_path and\n",
        "            self._h5f[\"positions\"][real_idx].astype(np.float32)\n",
        "        )\n",
        "        move_idx = int(self._h5f[\"move_idxs\"][real_idx])\n",
        "        outcome  = float(self._h5f[\"outcomes\"][real_idx])\n",
        "\n",
        "        return (\n",
        "            torch.from_numpy(\n",
        "                self._h5f[\"positions\"][real_idx].astype(np.float32)\n",
        "            ),\n",
        "            torch.tensor(move_idx, dtype=torch.long),\n",
        "            torch.tensor(outcome,  dtype=torch.float32)\n",
        "        )\n",
        "\n",
        "    def __del__(self):\n",
        "        if self._h5f is not None:\n",
        "            try:\n",
        "                self._h5f.close()\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "\n",
        "def create_hdf5_splits(\n",
        "    hdf5_path:  str,\n",
        "    n_total:    int,\n",
        "    val_ratio:  float = 0.10,\n",
        "    test_ratio: float = 0.05,\n",
        "    seed:       int   = SEED\n",
        "):\n",
        "    rng     = np.random.default_rng(seed)\n",
        "    indices = rng.permutation(n_total)\n",
        "\n",
        "    n_test  = int(n_total * test_ratio)\n",
        "    n_val   = int(n_total * val_ratio)\n",
        "    n_train = n_total - n_val - n_test\n",
        "\n",
        "    print(f\"Split ({n_total:,} positions) :\")\n",
        "    print(f\"  Train : {n_train:>10,}  ({n_train/n_total*100:.1f}%)\")\n",
        "    print(f\"  Val   : {n_val:>10,}  ({n_val/n_total*100:.1f}%)\")\n",
        "    print(f\"  Test  : {n_test:>10,}  ({n_test/n_total*100:.1f}%)\")\n",
        "\n",
        "    train_ds = ChessHDF5Dataset(hdf5_path, indices[:n_train])\n",
        "    val_ds   = ChessHDF5Dataset(hdf5_path, indices[n_train:n_train+n_val])\n",
        "    test_ds  = ChessHDF5Dataset(hdf5_path, indices[n_train+n_val:])\n",
        "\n",
        "    return train_ds, val_ds, test_ds\n",
        "\n",
        "\n",
        "BATCH_SIZE = 512\n",
        "\n",
        "train_ds, val_ds, test_ds = create_hdf5_splits(HDF5_PATH, total_positions)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          num_workers=2, pin_memory=True)\n",
        "\n",
        "print(f\"\\nDataLoaders prêts — batches train : {len(train_loader):,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyWYpnWY7sck",
        "outputId": "eac1fddc-3a02-4de9-a064-885ffd4f28da"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split (44,747,887 positions) :\n",
            "  Train : 38,035,705  (85.0%)\n",
            "  Val   :  4,474,788  (10.0%)\n",
            "  Test  :  2,237,394  (5.0%)\n",
            "\n",
            "DataLoaders prêts — batches train : 74,289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cellule 7 – Vérification et test rapide"
      ],
      "metadata": {
        "id": "YKl4Tg0G86Md"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELLULE 7 bis – Sanity check\n",
        "# ============================================================\n",
        "sample_pos, sample_moves, sample_outcomes = next(iter(train_loader))\n",
        "\n",
        "print(f\"Positions  : {sample_pos.shape}  dtype={sample_pos.dtype}\")\n",
        "print(f\"Moves      : {sample_moves.shape}  range=[{sample_moves.min()}, {sample_moves.max()}]\")\n",
        "print(f\"Outcomes   : {sample_outcomes.unique()}\")\n",
        "print(f\"UCI premier coup : {IDX2UCI[sample_moves[0].item()]}\")"
      ],
      "metadata": {
        "id": "TtpzHS8_7wFt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4218584a-35f7-4265-f81e-e094e7d5bc17"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positions  : torch.Size([512, 16, 8, 8])  dtype=torch.float32\n",
            "Moves      : torch.Size([512])  range=[3, 4536]\n",
            "Outcomes   : tensor([0.0000, 0.5000, 1.0000])\n",
            "UCI premier coup : g8h8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cellule 8 – Architecture ResNet"
      ],
      "metadata": {
        "id": "HcbIf8OsKmu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELLULE 8 – Architecture ResNet + Policy/Value Heads\n",
        "# ============================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Bloc résiduel standard :\n",
        "    Conv(3×3) → BN → ReLU → Conv(3×3) → BN → (+skip) → ReLU\n",
        "    \"\"\"\n",
        "    def __init__(self, channels: int):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(channels, channels,\n",
        "                               kernel_size=3, padding=1, bias=False)\n",
        "        self.bn1   = nn.BatchNorm2d(channels)\n",
        "        self.conv2 = nn.Conv2d(channels, channels,\n",
        "                               kernel_size=3, padding=1, bias=False)\n",
        "        self.bn2   = nn.BatchNorm2d(channels)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        residual = x\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.bn2(self.conv2(x))\n",
        "        return F.relu(x + residual)\n",
        "\n",
        "\n",
        "class ChessResNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Architecture ResNet pour les échecs.\n",
        "\n",
        "    Entrée  : [B, 16, 8, 8]\n",
        "    Sorties : logits_policy [B, 4672]\n",
        "              logit_value   [B, 1]\n",
        "\n",
        "    Paramètres totaux : ~7.2M (128 filtres, 10 blocs)\n",
        "    Mémoire GPU (fp16, batch=512) : ~3.5 Go\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels:   int = 16,\n",
        "        num_filters:   int = 128,\n",
        "        num_blocks:    int = 10,\n",
        "        policy_size:   int = 4672\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # ── Stem : conv initiale ──────────────────────────────────\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, num_filters,\n",
        "                      kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(num_filters),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # ── Corps : blocs résiduels ───────────────────────────────\n",
        "        self.res_blocks = nn.Sequential(\n",
        "            *[ResidualBlock(num_filters) for _ in range(num_blocks)]\n",
        "        )\n",
        "\n",
        "        # ── Policy Head ───────────────────────────────────────────\n",
        "        # Conv 1×1 : 128 → 2 filtres, puis FC → 4672 logits\n",
        "        self.policy_conv = nn.Sequential(\n",
        "            nn.Conv2d(num_filters, 2, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(2),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.policy_fc = nn.Linear(2 * 8 * 8, policy_size)\n",
        "\n",
        "        # ── Value Head ────────────────────────────────────────────\n",
        "        # Conv 1×1 : 128 → 1 filtre, puis FC(64) → FC(1) → sigmoid\n",
        "        self.value_conv = nn.Sequential(\n",
        "            nn.Conv2d(num_filters, 1, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.value_fc = nn.Sequential(\n",
        "            nn.Linear(1 * 8 * 8, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "        # ── Initialisation des poids ──────────────────────────────\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(\n",
        "                    m.weight, mode=\"fan_out\", nonlinearity=\"relu\"\n",
        "                )\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(\n",
        "        self, x: torch.Tensor\n",
        "    ):\n",
        "        # Trunk\n",
        "        x = self.stem(x)\n",
        "        x = self.res_blocks(x)\n",
        "\n",
        "        # Policy head\n",
        "        p = self.policy_conv(x)\n",
        "        p = p.view(p.size(0), -1)       # [B, 128]\n",
        "        logits_policy = self.policy_fc(p)  # [B, 4672]\n",
        "\n",
        "        # Value head\n",
        "        v = self.value_conv(x)\n",
        "        v = v.view(v.size(0), -1)       # [B, 64]\n",
        "        logit_value = self.value_fc(v)  # [B, 1]\n",
        "\n",
        "        return logits_policy, logit_value\n",
        "\n",
        "\n",
        "# ── Instanciation et vérification ────────────────────────────\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device : {DEVICE}\")\n",
        "\n",
        "model = ChessResNet(\n",
        "    in_channels = 16,\n",
        "    num_filters  = 128,\n",
        "    num_blocks   = 10,\n",
        "    policy_size  = len(UCI2IDX)\n",
        ").to(DEVICE)\n",
        "\n",
        "# Compte les paramètres\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "train_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Paramètres totaux    : {total_params:,}\")\n",
        "print(f\"Paramètres entraîn.  : {train_params:,}\")\n",
        "\n",
        "# Test forward pass\n",
        "with torch.no_grad():\n",
        "    dummy = torch.randn(4, 16, 8, 8).to(DEVICE)\n",
        "    pol, val = model(dummy)\n",
        "    print(f\"Policy output shape  : {pol.shape}\")\n",
        "    print(f\"Value output shape   : {val.shape}\")\n",
        "    print(\"Forward pass OK ✅\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpaVLRYcKMjn",
        "outputId": "8b2f52e4-19b1-4e7d-e841-fd833fdd7377"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device : cuda\n",
            "Paramètres totaux    : 3,563,719\n",
            "Paramètres entraîn.  : 3,563,719\n",
            "Policy output shape  : torch.Size([4, 4544])\n",
            "Value output shape   : torch.Size([4, 1])\n",
            "Forward pass OK ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cellule 9 – Fonctions de loss et métriques"
      ],
      "metadata": {
        "id": "ReGfg544KsJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELLULE 9 – Loss functions + métriques\n",
        "# ============================================================\n",
        "\n",
        "def compute_loss(\n",
        "    logits_policy: torch.Tensor,   # [B, 4672]\n",
        "    logit_value:   torch.Tensor,   # [B, 1]\n",
        "    target_moves:  torch.Tensor,   # [B]     int64\n",
        "    target_values: torch.Tensor,   # [B]     float32\n",
        "    value_weight:  float = 1.0\n",
        ") -> tuple:\n",
        "    \"\"\"\n",
        "    Calcule la loss totale et ses composantes.\n",
        "\n",
        "    policy_loss : CrossEntropy(logits, move_idx)\n",
        "    value_loss  : MSE(sigmoid(logit_value), target_value)\n",
        "    total_loss  : policy_loss + value_weight * value_loss\n",
        "    \"\"\"\n",
        "    # Policy loss\n",
        "    policy_loss = F.cross_entropy(logits_policy, target_moves)\n",
        "\n",
        "    # Value loss\n",
        "    pred_value  = torch.sigmoid(logit_value).squeeze(1)  # [B]\n",
        "    value_loss  = F.mse_loss(pred_value, target_values)\n",
        "\n",
        "    total_loss = policy_loss + value_weight * value_loss\n",
        "\n",
        "    return total_loss, policy_loss, value_loss\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_accuracy(\n",
        "    logits_policy: torch.Tensor,\n",
        "    target_moves:  torch.Tensor\n",
        ") -> tuple:\n",
        "    \"\"\"\n",
        "    Calcule Accuracy@1 et Accuracy@5.\n",
        "    \"\"\"\n",
        "    # Top-1\n",
        "    pred_top1  = logits_policy.argmax(dim=1)\n",
        "    acc1       = (pred_top1 == target_moves).float().mean().item()\n",
        "\n",
        "    # Top-5\n",
        "    top5_preds = logits_policy.topk(5, dim=1).indices  # [B, 5]\n",
        "    acc5       = (top5_preds == target_moves.unsqueeze(1)).any(dim=1).float().mean().item()\n",
        "\n",
        "    return acc1, acc5"
      ],
      "metadata": {
        "id": "3inxvV5_KRCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cellule 10 – Configuration entraînement"
      ],
      "metadata": {
        "id": "QBKl09opKzHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELLULE 10 – Hyperparamètres + optimizer + scheduler\n",
        "# ============================================================\n",
        "\n",
        "# ── Hyperparamètres ───────────────────────────────────────────\n",
        "NUM_EPOCHS    = 5\n",
        "LR_MAX        = 3e-3      # pic OneCycleLR\n",
        "LR_MIN        = 1e-5      # fin d'entraînement\n",
        "WEIGHT_DECAY  = 1e-4\n",
        "VALUE_WEIGHT  = 1.0       # pondération value loss\n",
        "GRAD_CLIP     = 1.0       # norme max du gradient\n",
        "CHECKPOINT_EVERY_N_BATCHES = 10_000   # sauvegarde toutes les 10k batches\n",
        "\n",
        "CHECKPOINT_DIR = os.path.join(OUTPUT_DIR, \"checkpoints\")\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# ── Optimizer ─────────────────────────────────────────────────\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr           = LR_MAX,\n",
        "    weight_decay = WEIGHT_DECAY\n",
        ")\n",
        "\n",
        "# ── Scheduler OneCycleLR ──────────────────────────────────────\n",
        "# Monte jusqu'à LR_MAX en 30% des steps, descend ensuite\n",
        "total_steps = NUM_EPOCHS * len(train_loader)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr          = LR_MAX,\n",
        "    total_steps     = total_steps,\n",
        "    pct_start       = 0.3,\n",
        "    anneal_strategy = \"cos\",\n",
        "    final_div_factor= LR_MAX / LR_MIN\n",
        ")\n",
        "\n",
        "# ── Mixed precision (AMP fp16) ────────────────────────────────\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
        "\n",
        "print(f\"Epochs          : {NUM_EPOCHS}\")\n",
        "print(f\"Batches/epoch   : {len(train_loader):,}\")\n",
        "print(f\"Steps totaux    : {total_steps:,}\")\n",
        "print(f\"LR max          : {LR_MAX}\")\n",
        "print(f\"LR min          : {LR_MIN}\")\n",
        "print(f\"Checkpoints     : {CHECKPOINT_DIR}\")"
      ],
      "metadata": {
        "id": "DYey9ehyKU1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cellule 11 – Boucle d'entraînement complète"
      ],
      "metadata": {
        "id": "bviLZpBNK6Jo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELLULE 11 – Boucle d'entraînement\n",
        "# ============================================================\n",
        "import time\n",
        "\n",
        "def save_checkpoint(\n",
        "    epoch:        int,\n",
        "    batch_idx:    int,\n",
        "    model:        nn.Module,\n",
        "    optimizer:    torch.optim.Optimizer,\n",
        "    scheduler,\n",
        "    scaler,\n",
        "    metrics:      dict,\n",
        "    path:         str\n",
        "):\n",
        "    torch.save({\n",
        "        \"epoch\":          epoch,\n",
        "        \"batch_idx\":      batch_idx,\n",
        "        \"model_state\":    model.state_dict(),\n",
        "        \"optimizer_state\":optimizer.state_dict(),\n",
        "        \"scheduler_state\":scheduler.state_dict(),\n",
        "        \"scaler_state\":   scaler.state_dict(),\n",
        "        \"metrics\":        metrics,\n",
        "        \"uci2idx\":        UCI2IDX,\n",
        "    }, path)\n",
        "\n",
        "\n",
        "def load_checkpoint(path: str, model, optimizer, scheduler, scaler):\n",
        "    \"\"\"Reprend l'entraînement depuis un checkpoint.\"\"\"\n",
        "    ckpt = torch.load(path, map_location=DEVICE)\n",
        "    model.load_state_dict(ckpt[\"model_state\"])\n",
        "    optimizer.load_state_dict(ckpt[\"optimizer_state\"])\n",
        "    scheduler.load_state_dict(ckpt[\"scheduler_state\"])\n",
        "    scaler.load_state_dict(ckpt[\"scaler_state\"])\n",
        "    print(f\"Checkpoint chargé : epoch {ckpt['epoch']}, \"\n",
        "          f\"batch {ckpt['batch_idx']}\")\n",
        "    return ckpt[\"epoch\"], ckpt[\"batch_idx\"], ckpt[\"metrics\"]\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate(model, val_loader, value_weight, device):\n",
        "    \"\"\"Passe de validation complète.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = total_policy = total_value = 0.0\n",
        "    total_acc1 = total_acc5  = 0.0\n",
        "    n_batches  = 0\n",
        "\n",
        "    for positions, moves, outcomes in tqdm(\n",
        "        val_loader, desc=\"Validation\", leave=False\n",
        "    ):\n",
        "        positions = positions.to(device, non_blocking=True)\n",
        "        moves     = moves.to(device, non_blocking=True)\n",
        "        outcomes  = outcomes.to(device, non_blocking=True)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            logits_policy, logit_value = model(positions)\n",
        "            loss, p_loss, v_loss = compute_loss(\n",
        "                logits_policy, logit_value,\n",
        "                moves, outcomes, value_weight\n",
        "            )\n",
        "\n",
        "        acc1, acc5 = compute_accuracy(logits_policy, moves)\n",
        "\n",
        "        total_loss   += loss.item()\n",
        "        total_policy += p_loss.item()\n",
        "        total_value  += v_loss.item()\n",
        "        total_acc1   += acc1\n",
        "        total_acc5   += acc5\n",
        "        n_batches    += 1\n",
        "\n",
        "    model.train()\n",
        "    return {\n",
        "        \"val_loss\":        total_loss   / n_batches,\n",
        "        \"val_policy_loss\": total_policy / n_batches,\n",
        "        \"val_value_loss\":  total_value  / n_batches,\n",
        "        \"val_acc1\":        total_acc1   / n_batches,\n",
        "        \"val_acc5\":        total_acc5   / n_batches,\n",
        "    }\n",
        "\n",
        "\n",
        "# ── Boucle principale ─────────────────────────────────────────\n",
        "def train(\n",
        "    model, optimizer, scheduler, scaler,\n",
        "    train_loader, val_loader,\n",
        "    num_epochs, value_weight, grad_clip,\n",
        "    checkpoint_dir, checkpoint_every_n_batches,\n",
        "    device,\n",
        "    start_epoch=0, start_batch=0\n",
        "):\n",
        "    model.train()\n",
        "    history = []\n",
        "    best_val_acc1  = 0.0\n",
        "    best_ckpt_path = os.path.join(checkpoint_dir, \"best_model.pt\")\n",
        "\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        epoch_start = time.time()\n",
        "\n",
        "        # Métriques running (réinitialisées chaque epoch)\n",
        "        run_loss = run_policy = run_value = 0.0\n",
        "        run_acc1 = run_acc5  = 0.0\n",
        "        n_batches = 0\n",
        "\n",
        "        pbar = tqdm(\n",
        "            enumerate(train_loader),\n",
        "            total=len(train_loader),\n",
        "            desc=f\"Epoch {epoch+1}/{num_epochs}\"\n",
        "        )\n",
        "\n",
        "        for batch_idx, (positions, moves, outcomes) in pbar:\n",
        "\n",
        "            # Ignore les batches déjà traités si reprise\n",
        "            if epoch == start_epoch and batch_idx < start_batch:\n",
        "                continue\n",
        "\n",
        "            positions = positions.to(device, non_blocking=True)\n",
        "            moves     = moves.to(device, non_blocking=True)\n",
        "            outcomes  = outcomes.to(device, non_blocking=True)\n",
        "\n",
        "            # ── Forward (fp16) ────────────────────────────────\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with torch.cuda.amp.autocast():\n",
        "                logits_policy, logit_value = model(positions)\n",
        "                loss, p_loss, v_loss = compute_loss(\n",
        "                    logits_policy, logit_value,\n",
        "                    moves, outcomes, value_weight\n",
        "                )\n",
        "\n",
        "            # ── Backward + gradient clipping ──────────────────\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "\n",
        "            # ── Métriques running ─────────────────────────────\n",
        "            acc1, acc5 = compute_accuracy(logits_policy, moves)\n",
        "            run_loss   += loss.item()\n",
        "            run_policy += p_loss.item()\n",
        "            run_value  += v_loss.item()\n",
        "            run_acc1   += acc1\n",
        "            run_acc5   += acc5\n",
        "            n_batches  += 1\n",
        "\n",
        "            # Mise à jour barre\n",
        "            if n_batches % 100 == 0:\n",
        "                pbar.set_postfix({\n",
        "                    \"loss\":   f\"{run_loss/n_batches:.4f}\",\n",
        "                    \"acc@1\":  f\"{run_acc1/n_batches*100:.1f}%\",\n",
        "                    \"acc@5\":  f\"{run_acc5/n_batches*100:.1f}%\",\n",
        "                    \"lr\":     f\"{scheduler.get_last_lr()[0]:.2e}\"\n",
        "                })\n",
        "\n",
        "            # ── Checkpoint périodique ─────────────────────────\n",
        "            if (batch_idx + 1) % checkpoint_every_n_batches == 0:\n",
        "                ckpt_path = os.path.join(\n",
        "                    checkpoint_dir,\n",
        "                    f\"ckpt_e{epoch+1}_b{batch_idx+1}.pt\"\n",
        "                )\n",
        "                save_checkpoint(\n",
        "                    epoch, batch_idx, model, optimizer,\n",
        "                    scheduler, scaler,\n",
        "                    {\"batch_loss\": run_loss / n_batches},\n",
        "                    ckpt_path\n",
        "                )\n",
        "                print(f\"\\n  → Checkpoint sauvegardé : {ckpt_path}\")\n",
        "\n",
        "        # ── Validation fin d'epoch ────────────────────────────\n",
        "        val_metrics = validate(\n",
        "            model, val_loader, value_weight, device\n",
        "        )\n",
        "\n",
        "        epoch_time = (time.time() - epoch_start) / 60\n",
        "\n",
        "        train_metrics = {\n",
        "            \"epoch\":             epoch + 1,\n",
        "            \"train_loss\":        run_loss   / n_batches,\n",
        "            \"train_policy_loss\": run_policy / n_batches,\n",
        "            \"train_value_loss\":  run_value  / n_batches,\n",
        "            \"train_acc1\":        run_acc1   / n_batches,\n",
        "            \"train_acc5\":        run_acc5   / n_batches,\n",
        "            \"epoch_time_min\":    epoch_time,\n",
        "            **val_metrics\n",
        "        }\n",
        "        history.append(train_metrics)\n",
        "\n",
        "        print(f\"\\n{'='*65}\")\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}  ({epoch_time:.1f} min)\")\n",
        "        print(f\"  Train  loss={train_metrics['train_loss']:.4f}  \"\n",
        "              f\"acc@1={train_metrics['train_acc1']*100:.2f}%  \"\n",
        "              f\"acc@5={train_metrics['train_acc5']*100:.2f}%\")\n",
        "        print(f\"  Val    loss={val_metrics['val_loss']:.4f}  \"\n",
        "              f\"acc@1={val_metrics['val_acc1']*100:.2f}%  \"\n",
        "              f\"acc@5={val_metrics['val_acc5']*100:.2f}%\")\n",
        "        print(f\"{'='*65}\\n\")\n",
        "\n",
        "        # ── Sauvegarde du meilleur modèle ─────────────────────\n",
        "        if val_metrics[\"val_acc1\"] > best_val_acc1:\n",
        "            best_val_acc1 = val_metrics[\"val_acc1\"]\n",
        "            save_checkpoint(\n",
        "                epoch, len(train_loader), model, optimizer,\n",
        "                scheduler, scaler, train_metrics, best_ckpt_path\n",
        "            )\n",
        "            print(f\"  ★ Meilleur modèle sauvegardé \"\n",
        "                  f\"(val_acc@1={best_val_acc1*100:.2f}%)\\n\")\n",
        "\n",
        "        # Checkpoint fin d'epoch\n",
        "        epoch_ckpt = os.path.join(\n",
        "            checkpoint_dir, f\"epoch_{epoch+1}_final.pt\"\n",
        "        )\n",
        "        save_checkpoint(\n",
        "            epoch, len(train_loader), model, optimizer,\n",
        "            scheduler, scaler, train_metrics, epoch_ckpt\n",
        "        )\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "# ── Lancement ─────────────────────────────────────────────────\n",
        "history = train(\n",
        "    model         = model,\n",
        "    optimizer     = optimizer,\n",
        "    scheduler     = scheduler,\n",
        "    scaler        = scaler,\n",
        "    train_loader  = train_loader,\n",
        "    val_loader    = val_loader,\n",
        "    num_epochs    = NUM_EPOCHS,\n",
        "    value_weight  = VALUE_WEIGHT,\n",
        "    grad_clip     = GRAD_CLIP,\n",
        "    checkpoint_dir= CHECKPOINT_DIR,\n",
        "    checkpoint_every_n_batches = CHECKPOINT_EVERY_N_BATCHES,\n",
        "    device        = DEVICE,\n",
        "    start_epoch   = 0,\n",
        "    start_batch   = 0\n",
        ")"
      ],
      "metadata": {
        "id": "I9mP3qsiKfLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cellule 12 – Reprise après crash (optionnelle)"
      ],
      "metadata": {
        "id": "7tf4H0LGLDGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELLULE 12 – Reprise depuis checkpoint si session plantée\n",
        "# ============================================================\n",
        "\n",
        "# Décommente et adapte le chemin si Colab crashe en cours de route\n",
        "\n",
        "# RESUME_FROM = os.path.join(CHECKPOINT_DIR, \"ckpt_e1_b10000.pt\")\n",
        "# start_epoch, start_batch, saved_metrics = load_checkpoint(\n",
        "#     RESUME_FROM, model, optimizer, scheduler, scaler\n",
        "# )\n",
        "# history = train(\n",
        "#     model, optimizer, scheduler, scaler,\n",
        "#     train_loader, val_loader,\n",
        "#     num_epochs    = NUM_EPOCHS,\n",
        "#     value_weight  = VALUE_WEIGHT,\n",
        "#     grad_clip     = GRAD_CLIP,\n",
        "#     checkpoint_dir= CHECKPOINT_DIR,\n",
        "#     checkpoint_every_n_batches = CHECKPOINT_EVERY_N_BATCHES,\n",
        "#     device        = DEVICE,\n",
        "#     start_epoch   = start_epoch,\n",
        "#     start_batch   = start_batch + 1\n",
        "# )"
      ],
      "metadata": {
        "id": "3ajXElxrLKcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cellule 13 – Courbes d'apprentissage"
      ],
      "metadata": {
        "id": "JGyjjRozLQRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELLULE 13 – Visualisation des courbes\n",
        "# ============================================================\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_history(history: list):\n",
        "    epochs = [h[\"epoch\"] for h in history]\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
        "\n",
        "    # Loss\n",
        "    axes[0].plot(epochs, [h[\"train_loss\"] for h in history],\n",
        "                 label=\"Train\", marker=\"o\")\n",
        "    axes[0].plot(epochs, [h[\"val_loss\"] for h in history],\n",
        "                 label=\"Val\",   marker=\"s\")\n",
        "    axes[0].set_title(\"Loss totale\")\n",
        "    axes[0].set_xlabel(\"Epoch\")\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True)\n",
        "\n",
        "    # Accuracy@1\n",
        "    axes[1].plot(epochs, [h[\"train_acc1\"]*100 for h in history],\n",
        "                 label=\"Train acc@1\", marker=\"o\")\n",
        "    axes[1].plot(epochs, [h[\"val_acc1\"]*100 for h in history],\n",
        "                 label=\"Val acc@1\",   marker=\"s\")\n",
        "    axes[1].set_title(\"Policy Accuracy@1 (%)\")\n",
        "    axes[1].set_xlabel(\"Epoch\")\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True)\n",
        "\n",
        "    # Accuracy@5\n",
        "    axes[2].plot(epochs, [h[\"train_acc5\"]*100 for h in history],\n",
        "                 label=\"Train acc@5\", marker=\"o\")\n",
        "    axes[2].plot(epochs, [h[\"val_acc5\"]*100 for h in history],\n",
        "                 label=\"Val acc@5\",   marker=\"s\")\n",
        "    axes[2].set_title(\"Policy Accuracy@5 (%)\")\n",
        "    axes[2].set_xlabel(\"Epoch\")\n",
        "    axes[2].legend()\n",
        "    axes[2].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(OUTPUT_DIR, \"training_curves.png\"), dpi=120)\n",
        "    plt.show()\n",
        "    print(\"Courbes sauvegardées sur Drive.\")\n",
        "\n",
        "if history:\n",
        "    plot_history(history)"
      ],
      "metadata": {
        "id": "MBHMlsngLUl9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}